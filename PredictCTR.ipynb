{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check how diverse is the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_dict(d):\n",
    "    user_tags = d['user_tags'].split(',')\n",
    "    del d['user_tags']\n",
    "    for tag in user_tags:\n",
    "        d['tag_' + tag] = True\n",
    "    del d['click']  # Click is the target variable.\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "field_names = ['click', 'weekday', 'hour', 'timestamp', 'log_type', 'user_id', 'user_agent',\n",
    "               'ip', 'region', 'city', 'ad_exchange', 'domain', 'url', 'anonymous_url_id', \n",
    "               'ad_slot_id', 'ad_slot_width', 'ad_slot_height', 'ad_slot_visibility', 'ad_slot_format',\n",
    "               'ad_slot_floor_price', 'creative_id', 'key_page_url', 'advertiser_id', 'user_tags']\n",
    "l = []\n",
    "with open('train.txt') as f:\n",
    "    reader = csv.DictReader(f, delimiter='\\t', fieldnames=field_names)\n",
    "    for row in reader:\n",
    "        d = parse_dict(row)\n",
    "        l.append(d)\n",
    "        if len(l) > 100000:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set_keys = set()\n",
    "for d in l:\n",
    "    for key in d:\n",
    "        set_keys.add(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_exchange 3\n",
      "ad_slot_floor_price 92\n",
      "ad_slot_format 3\n",
      "ad_slot_height 6\n",
      "ad_slot_id 7135\n",
      "ad_slot_visibility 4\n",
      "ad_slot_width 11\n",
      "advertiser_id 1\n",
      "anonymous_url_id 1\n",
      "city 368\n",
      "creative_id 11\n",
      "domain 3475\n",
      "hour 11\n",
      "ip 65488\n",
      "key_page_url 2\n",
      "log_type 1\n",
      "region 35\n",
      "timestamp 90971\n",
      "url 35194\n",
      "user_agent 31\n",
      "user_id 90574\n",
      "weekday 1\n"
     ]
    }
   ],
   "source": [
    "for key in sorted(set_keys):\n",
    "    if key.startswith('tag_'):\n",
    "        continue\n",
    "    print(key, len(set([x[key] for x in l if key in x])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As result of this, we choose, as a start, to throw out `ip`, `user_id`, `url`, `timestamp`, `domain`, `city`, `ad_slot_id` fields as they would lead to too many features.\n",
    "Also remove fields that have no diversity, like `advertiser_id` and `log_type`.\n",
    "\n",
    "# Convert dataset into encoded features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "float_fields = ['ad_slot_floor_price', 'ad_slot_height', 'ad_slot_width', 'hour']\n",
    "remove_fields = ['ip', 'user_id', 'url', 'timestamp', 'domain', 'city', 'ad_slot_id', 'log_type', 'advertiser_id', 'anonymous_url_id']\n",
    "def parse_dict(d):\n",
    "    user_tags = d['user_tags'].split(',')\n",
    "    del d['user_tags']\n",
    "    #for tag in user_tags:\n",
    "    #    d['tag_' + tag] = True\n",
    "    del d['click']  # Click is the target variable.\n",
    "    for ff in float_fields:\n",
    "        d[ff] = float(d[ff])\n",
    "    for f in remove_fields:\n",
    "        del d[f]\n",
    "    user_agent = d['user_agent']\n",
    "    os, browser = user_agent.split('_')\n",
    "    d['os'] = os\n",
    "    d['browser'] = browser\n",
    "    del d['user_agent']\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use first million data points to train the DictVectorizer.\n",
    "l = []\n",
    "with open('train.txt') as f:\n",
    "    reader = csv.DictReader(f, delimiter='\\t', fieldnames=field_names)\n",
    "    for row in reader:\n",
    "        d = parse_dict(row)\n",
    "        l.append(d)\n",
    "        if len(l) == 1000000:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dv = DictVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
       "        sparse=True)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv.fit(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ad_exchange=1',\n",
       " 'ad_exchange=2',\n",
       " 'ad_exchange=3',\n",
       " 'ad_slot_floor_price',\n",
       " 'ad_slot_format=0',\n",
       " 'ad_slot_format=1',\n",
       " 'ad_slot_format=5',\n",
       " 'ad_slot_height',\n",
       " 'ad_slot_visibility=0',\n",
       " 'ad_slot_visibility=1',\n",
       " 'ad_slot_visibility=2',\n",
       " 'ad_slot_visibility=255',\n",
       " 'ad_slot_width',\n",
       " 'browser=chrome',\n",
       " 'browser=firefox',\n",
       " 'browser=ie',\n",
       " 'browser=maxthon',\n",
       " 'browser=opera',\n",
       " 'browser=other',\n",
       " 'browser=safari',\n",
       " 'browser=sogou',\n",
       " 'browser=theworld',\n",
       " 'creative_id=011c1a3d4d3f089a54f9b70a4c0a6eb3',\n",
       " 'creative_id=2f88fc9cf0141b5bbaf251cab07f4ce7',\n",
       " 'creative_id=44966cc8da1ed40c95d59e863c8c75f0',\n",
       " 'creative_id=47905feeb59223468fb898b3c9ac024d',\n",
       " 'creative_id=6cdf8fdd3e01122b09b5b411510a2385',\n",
       " 'creative_id=7097e4210dea4d69f07f0f5e4343529c',\n",
       " 'creative_id=82f125e356439d73902ae85e2be96777',\n",
       " 'creative_id=86c2543527c86a893d4d4f68810a0416',\n",
       " 'creative_id=b90c12ed2bd7950c6027bf9c6937c48a',\n",
       " 'creative_id=e87d7633d474589c2e2e3ba4eda53f6c',\n",
       " 'creative_id=ff5123fb9333ca095034c62fdaaf51aa',\n",
       " 'hour',\n",
       " 'key_page_url=361e128affece850342293213691a043',\n",
       " 'key_page_url=43f4a37f42a7c5e6219e2601b26c6976',\n",
       " 'os=android',\n",
       " 'os=ios',\n",
       " 'os=linux',\n",
       " 'os=mac',\n",
       " 'os=other',\n",
       " 'os=windows',\n",
       " 'weekday=0',\n",
       " 'weekday=1',\n",
       " 'weekday=6']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check what features we have.\n",
    "print(len(dv.get_feature_names()))\n",
    "dv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# At this point we are ready to transform the data and output into a new CSV file.\n",
    "field_names = ['click', 'weekday', 'hour', 'timestamp', 'log_type', 'user_id', 'user_agent',\n",
    "               'ip', 'region', 'city', 'ad_exchange', 'domain', 'url', 'anonymous_url_id', \n",
    "               'ad_slot_id', 'ad_slot_width', 'ad_slot_height', 'ad_slot_visibility', 'ad_slot_format',\n",
    "               'ad_slot_floor_price', 'creative_id', 'key_page_url', 'advertiser_id', 'user_tags']\n",
    "l = []\n",
    "targets = []\n",
    "with open('train.txt') as f:\n",
    "    reader = csv.DictReader(f, delimiter='\\t', fieldnames=field_names)\n",
    "    for row in reader:\n",
    "        targets.append(int(row['click']))\n",
    "        d = parse_dict(row)\n",
    "        l.append(d)\n",
    "        if len(l) == 5000:\n",
    "            features = dv.transform(l)\n",
    "            l = []\n",
    "            targets = []\n",
    "    if len(l) > 0:\n",
    "        features = dv.transform(l)\n",
    "        l = []\n",
    "        targets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# At this point we are ready to transform the data and output into a new CSV file.\n",
    "field_names = ['click', 'weekday', 'hour', 'timestamp', 'log_type', 'user_id', 'user_agent',\n",
    "               'ip', 'region', 'city', 'ad_exchange', 'domain', 'url', 'anonymous_url_id', \n",
    "               'ad_slot_id', 'ad_slot_width', 'ad_slot_height', 'ad_slot_visibility', 'ad_slot_format',\n",
    "               'ad_slot_floor_price', 'creative_id', 'key_page_url', 'advertiser_id', 'user_tags']\n",
    "l = []\n",
    "targets = []\n",
    "with open('train.processed.txt', 'wb') as of1, open('train.targets.txt', 'wb') as of2, open('train.txt') as f:\n",
    "    reader = csv.DictReader(f, delimiter='\\t', fieldnames=field_names)\n",
    "    for row in reader:\n",
    "        targets.append(int(row['click']))\n",
    "        d = parse_dict(row)\n",
    "        l.append(d)\n",
    "        if len(l) == 5000:\n",
    "            features = dv.transform(l)\n",
    "            l = []\n",
    "            np.savetxt(of1, features.toarray(), fmt='%d', delimiter=',')\n",
    "            np.savetxt(of2, targets, fmt='%d')\n",
    "            targets = []\n",
    "    if len(l) > 0:\n",
    "        features = dv.transform(l)\n",
    "        l = []\n",
    "        np.savetxt(of1, features.toarray(), fmt='%d', delimiter=',')\n",
    "        np.savetxt(of2, targets)\n",
    "        targets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "689.8324089050293"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2847802*2*127/1024/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = np.loadtxt('train.processed.txt', dtype='int16', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 1, 0, ..., 0, 0, 1],\n",
       "       [0, 1, 0, ..., 0, 0, 1],\n",
       "       ..., \n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0]], dtype=int16)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2847802, 45)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = d[:2000000]\n",
    "test = d[2000000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
